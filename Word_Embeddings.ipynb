{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Embeddings.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPNxUp1VSXHO3/ggoCMGakk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpradeesh3800/ml/blob/master/Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JJkw_PCUwFg",
        "colab_type": "text"
      },
      "source": [
        "*References*\n",
        "\n",
        "https://www.tensorflow.org/tutorials/text/word_embeddings\n",
        "\n",
        "https://keras.io/layers/embeddings/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_71PJNBgc-rE",
        "colab_type": "text"
      },
      "source": [
        "*Make sure that you install following packages to ensure that it works as expected*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-20XwUEKcs9",
        "colab_type": "code",
        "outputId": "9f1192bf-ae80-4db0-b8fc-be5be6c3915c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install gast==0.2.2\n",
        "!pip install tensorflow_federated==0.7.0\n",
        "!pip install -q tf-nightly"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.0.2\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Collecting tensorflow_federated==0.7.0\n",
            "  Downloading tensorflow_federated-0.7.0-py2.py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated==0.7.0) (1.18.1)\n",
            "Collecting attrs~=18.2\n",
            "  Downloading attrs-18.2.0-py2.py3-none-any.whl (34 kB)\n",
            "Collecting tf-nightly\n",
            "  Downloading tf_nightly-2.2.0.dev20200318-cp36-cp36m-manylinux2010_x86_64.whl (533.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 533.0 MB 11 kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py~=2.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated==0.7.0) (2.8.0)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated==0.7.0) (1.3.1)\n",
            "Collecting grpcio~=1.8.0\n",
            "  Downloading grpcio-1.8.6-cp36-cp36m-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 46.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated==0.7.0) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tensorflow_federated==0.7.0) (1.1.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tensorflow_federated==0.7.0) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tensorflow_federated==0.7.0) (3.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tensorflow_federated==0.7.0) (0.1.8)\n",
            "Collecting tb-nightly<2.3.0a0,>=2.2.0a0\n",
            "  Downloading tb_nightly-2.2.0a20200318-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 62.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tensorflow_federated==0.7.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tensorflow_federated==0.7.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tensorflow_federated==0.7.0) (3.10.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tensorflow_federated==0.7.0) (1.4.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly->tensorflow_federated==0.7.0) (0.34.2)\n",
            "Collecting astunparse==1.6.3\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting tf-estimator-nightly\n",
            "  Downloading tf_estimator_nightly-2.3.0.dev2020031801-py2.py3-none-any.whl (454 kB)\n",
            "\u001b[K     |████████████████████████████████| 454 kB 71.0 MB/s \n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.6.0.post2-py3-none-any.whl (775 kB)\n",
            "\u001b[K     |████████████████████████████████| 775 kB 55.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (45.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (3.2.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (2.21.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (1.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (1.3.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (3.1.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (2019.11.28)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly->tensorflow_federated==0.7.0) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tb-nightly 2.2.0a20200318 has requirement grpcio>=1.24.3, but you'll have grpcio 1.8.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tf-nightly 2.2.0.dev20200318 has requirement h5py<2.11.0,>=2.10.0, but you'll have h5py 2.8.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: attrs, gast, tensorboard-plugin-wit, grpcio, tb-nightly, astunparse, tf-estimator-nightly, tf-nightly, tensorflow-federated\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 19.3.0\n",
            "    Uninstalling attrs-19.3.0:\n",
            "      Successfully uninstalled attrs-19.3.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.2.2\n",
            "    Uninstalling gast-0.2.2:\n",
            "      Successfully uninstalled gast-0.2.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.24.3\n",
            "    Uninstalling grpcio-1.24.3:\n",
            "      Successfully uninstalled grpcio-1.24.3\n",
            "  Attempting uninstall: tensorflow-federated\n",
            "    Found existing installation: tensorflow-federated 0.12.0\n",
            "    Uninstalling tensorflow-federated-0.12.0:\n",
            "      Successfully uninstalled tensorflow-federated-0.12.0\n",
            "Successfully installed astunparse-1.6.3 attrs-18.2.0 gast-0.3.3 grpcio-1.8.6 tb-nightly-2.2.0a20200318 tensorboard-plugin-wit-1.6.0.post2 tensorflow-federated-0.7.0 tf-estimator-nightly-2.3.0.dev2020031801 tf-nightly-2.2.0.dev20200318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "grpc"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.9 MB 2.9 MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beH0PL6yKugC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9md04_GLBmT",
        "colab_type": "code",
        "outputId": "ee592a1c-c210-4963-b148-c4a59a7c8304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-dev20200318'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK7PacAGMZCO",
        "colab_type": "text"
      },
      "source": [
        "*We know that a text cannot be inputted into neural network as such.It has to be processed before being fed into NN.*\n",
        "\n",
        "*Each sentence can be seen as list of tokens(like words or substrings)*\n",
        "\n",
        "*Each Token can be represented as a Integer number. The Maximum value of the Token is known as input_dim. This means no token has been mapped to a greater than  or equal to input_dim*\n",
        "\n",
        "*Each Token has to be mapped to a 1D vector(This is embedding) of fixed size and it is trainable. The dimension of the vector is to be mentioned (it is a hyperparameters) and it is known as output_dim.*\n",
        "\n",
        "*Each sequence is a list of tokens of different size.So, we will pad zeros at the end.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YTQUOkGTBx4",
        "colab_type": "text"
      },
      "source": [
        "**tf.keras.layers.Embedding(input_dim,output_dim)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6moLRFZCMB8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(1000,5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsipWb4WTMBv",
        "colab_type": "code",
        "outputId": "c5bdcc20-b8f3-4af1-d15c-d07da0f8c31a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x = embedding_layer(tf.constant(2))\n",
        "x.numpy()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00838083,  0.00927347, -0.01304644,  0.01269159, -0.01352956],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg3ZaPLxTVeb",
        "colab_type": "code",
        "outputId": "62afb3cc-48e9-4305-b70c-95c73ccdb245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x = embedding_layer(tf.constant(999))\n",
        "x.numpy()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.04020435, -0.01292528, -0.04991257, -0.0295392 , -0.01072909],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alq4DRMPUP7n",
        "colab_type": "text"
      },
      "source": [
        "*Token value cannot be equal to input_dim*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuOoHunkTdV5",
        "colab_type": "code",
        "outputId": "ccce3631-5e5f-411b-947e-dbf1b464ab27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "x = embedding_layer(tf.constant(1000))\n",
        "x.numpy()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-bd401428b228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    971\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 972\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/embeddings.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'int32'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'int64'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36membedding_lookup\u001b[0;34m(params, ids, partition_strategy, name, validate_indices, max_norm)\u001b[0m\n\u001b[1;32m    324\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m       \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m       transform_fn=None)\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36m_embedding_lookup_and_transform\u001b[0;34m(params, ids, partition_strategy, name, max_norm, transform_fn)\u001b[0m\n\u001b[1;32m    135\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         result = _clip(\n\u001b[0;32m--> 137\u001b[0;31m             array_ops.gather(params[0], ids, name=name), ids, max_norm)\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransform_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4520\u001b[0m     \u001b[0;31m# TODO(apassos) find a less bad way of detecting resource variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4521\u001b[0m     \u001b[0;31m# without introducing a circular dependency.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4522\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4523\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4524\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36msparse_read\u001b[0;34m(self, indices, name)\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m       value = gen_resource_variable_ops.resource_gather(\n\u001b[0;32m--> 677\u001b[0;31m           self._handle, indices, dtype=self._dtype, name=name)\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mresource_gather\u001b[0;34m(resource, indices, dtype, batch_dims, validate_indices, name)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6778\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6779\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6780\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6781\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: indices = 1000 is not in [0, 1000) [Op:ResourceGather]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNLGkGv3T9dJ",
        "colab_type": "text"
      },
      "source": [
        "if input to embedding_layer is of size (x,)\n",
        "The output of the embedding layer is of size (x,output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBPguTtUTpfP",
        "colab_type": "code",
        "outputId": "c4eed6e5-1973-45d1-c04b-88ab2ecd5340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "x = embedding_layer(tf.constant([1,2,3]))\n",
        "x.numpy()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.03861893,  0.03799578, -0.02285944, -0.04729235, -0.03754127],\n",
              "       [ 0.00838083,  0.00927347, -0.01304644,  0.01269159, -0.01352956],\n",
              "       [-0.01134779, -0.02453787, -0.00169013, -0.04312469, -0.02912997]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgI68VDkUagX",
        "colab_type": "text"
      },
      "source": [
        "*if input to embedding_layer is of size (x,y) The output of the embedding layer is of size (x,y,output_dim)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rmLQFs1T1K0",
        "colab_type": "code",
        "outputId": "65bad588-1b56-46c5-d21d-ac8541cc6080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "x = embedding_layer(tf.constant([[1,2,3],[4,5,6]]))\n",
        "x.numpy()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.03861893,  0.03799578, -0.02285944, -0.04729235,\n",
              "         -0.03754127],\n",
              "        [ 0.00838083,  0.00927347, -0.01304644,  0.01269159,\n",
              "         -0.01352956],\n",
              "        [-0.01134779, -0.02453787, -0.00169013, -0.04312469,\n",
              "         -0.02912997]],\n",
              "\n",
              "       [[-0.0190549 ,  0.02655848,  0.02650747,  0.03201841,\n",
              "          0.00613926],\n",
              "        [-0.02125731, -0.02225229,  0.02481966, -0.03849624,\n",
              "         -0.00283132],\n",
              "        [ 0.00096061,  0.01598182,  0.01984005,  0.04290893,\n",
              "         -0.00679637]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buihfh5zLDvw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f6f4f399-b86e-4fa0-c2ab-5b49b2713cec"
      },
      "source": [
        "(train_data,test_data),info = tfds.load(\n",
        "    'imdb_reviews/subwords8k', \n",
        "    split = (tfds.Split.TRAIN, tfds.Split.TEST), \n",
        "    with_info=True, as_supervised=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset imdb_reviews/subwords8k/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0...\u001b[0m\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incompleteKJ2LQV/imdb_reviews-train.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incompleteKJ2LQV/imdb_reviews-test.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incompleteKJ2LQV/imdb_reviews-unsupervised.tfrecord\n",
            "\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl349ZflVnJ0",
        "colab_type": "text"
      },
      "source": [
        "*info has the encoder,which encodes tokens to integer values and decodes integer values to tokens*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZwBsdOyLWAn",
        "colab_type": "code",
        "outputId": "3f08d3c2-926c-438a-8a71-03611696c7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(info)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow_datasets.core.dataset_info.DatasetInfo"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2Qw2NQDWJRP",
        "colab_type": "code",
        "outputId": "c972a1c5-1932-4366-caa8-46374bf6e321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "info.features"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FeaturesDict({\n",
              "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
              "    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqG3retNY_-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = info.features['text'].encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znOGMzSSZkNz",
        "colab_type": "code",
        "outputId": "2e168818-5fa8-4d3d-8242-fd1d4eb211e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoder"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SubwordTextEncoder vocab_size=8185>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33A4rR1YZrxB",
        "colab_type": "code",
        "outputId": "4dc2b165-9bcb-4ea6-c0c3-6440887c086d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoder.vocab_size"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8185"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAXt9WIFZuiU",
        "colab_type": "code",
        "outputId": "cbc39059-a67a-4fa7-bf6c-937d1a084307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(encoder.subwords),type(encoder.subwords)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7928, list)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEeows6sae6P",
        "colab_type": "text"
      },
      "source": [
        "*underscore means space*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQP2_JqYZ0Nk",
        "colab_type": "code",
        "outputId": "16553e76-7b2c-47a5-e1d9-2aaf75600715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "encoder.subwords[:20]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the_',\n",
              " ', ',\n",
              " '. ',\n",
              " 'a_',\n",
              " 'and_',\n",
              " 'of_',\n",
              " 'to_',\n",
              " 's_',\n",
              " 'is_',\n",
              " 'br',\n",
              " 'in_',\n",
              " 'I_',\n",
              " 'that_',\n",
              " 'this_',\n",
              " 'it_',\n",
              " ' /><',\n",
              " ' />',\n",
              " 'was_',\n",
              " 'The_',\n",
              " 'as_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5h5sUhKaW3P",
        "colab_type": "code",
        "outputId": "b9fd8d92-5349-42b9-dfc8-bd13e1a454d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_string = \"Pradeeshwar JaiShankar\"\n",
        "encoded_string = encoder.encode(sample_string)\n",
        "encoded_string"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7168, 1816, 190, 8033, 904, 836, 8034, 6030, 7206]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IUkTNdqfXCY",
        "colab_type": "code",
        "outputId": "4c716756-5adf-4688-e37d-38e60e3030e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "for i in encoded_string:\n",
        "    print(\"'{}'\".format(encoder.decode([i])))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Pr'\n",
            "'ade'\n",
            "'es'\n",
            "'h'\n",
            "'war '\n",
            "'Ja'\n",
            "'i'\n",
            "'Shan'\n",
            "'kar'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbOAJv8kfuI4",
        "colab_type": "code",
        "outputId": "970cc690-7fa8-4e75-ad50-6d844c324a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoded_string = encoder.decode(encoded_string)\n",
        "decoded_string"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Pradeeshwar JaiShankar'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57wSRP5qhLf3",
        "colab_type": "code",
        "outputId": "82c89321-504a-4e81-c958-480d55a3e85a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((None,), ()), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETbO4apW5AwK",
        "colab_type": "text"
      },
      "source": [
        "*Dataset is made into batches and padded with zeros*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kVZUheDgVbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batches  = train_data.shuffle(1000).padded_batch(10)\n",
        "test_batches = test_data.padded_batch(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyWzVKUSjkGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_batch  = next(iter(train_batches))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qra_G1vQ4LbJ",
        "colab_type": "code",
        "outputId": "3454432d-de26-4bb0-a46a-cb915bc171ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "data,label = sample_batch\n",
        "print(data.numpy(),label.numpy(),sep='\\n\\n')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  69   57   93 ...    0    0    0]\n",
            " [ 133  279   86 ...    0    0    0]\n",
            " [1566  160 2124 ...    0    0    0]\n",
            " ...\n",
            " [ 147   82 1622 ...    0    0    0]\n",
            " [7963  134  404 ... 7974  166 7962]\n",
            " [  69  117   31 ...    0    0    0]]\n",
            "\n",
            "[1 1 0 1 0 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r59sSMzr6Cga",
        "colab_type": "text"
      },
      "source": [
        "*Every padded with according to longest sequence in the batch.Hence the size of each batch is different*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lwXyhcv5V4k",
        "colab_type": "code",
        "outputId": "b0bfdaa7-e820-4593-ea10-6bbe53970056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "for data,label in train_batches.take(3):\n",
        "    print(\"{:20s} : {}\".format(\"batch size\",data.numpy().shape),end='\\n\\n')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch size           : (10, 455)\n",
            "\n",
            "batch size           : (10, 539)\n",
            "\n",
            "batch size           : (10, 754)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJagPGfD5MBY",
        "colab_type": "text"
      },
      "source": [
        "*Now the Dataset is ready to train*"
      ]
    }
  ]
}